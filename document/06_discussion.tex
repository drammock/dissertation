\chapter{Discussion\label{chap:Discussion}}
% TODO: check for interaction between base intelligibility of training talker, and improvement across quartiles.

It is well\-/known that speakers of a language may use different articulatory means to achieve the same goals.  Examples of such free variation abound, from the various articulations of English /ɹ/ \citep{Hagiwara1995, CampbellEtAl2010} to the gestural combinations used in conveying stress or prominence \citep{deJong1995}.  In that sense, the finding that talkers vary in their strategies toward intelligibility is unsurprising, and has a clear theoretical forerunner in the H\&H theory of \citet{Lindblom1990}.

Nonetheless, the individual differences in intelligibility strategies seen here are interesting when viewed in light of the information present in the speech signal.  That is, some talkers (such as Talker~\ac{a} in these experiments) seem to maintain a higher information density at the segmental level of their speech, making them relatively intelligible even when the low-frequency modulations of their speech do little to enhance the successful transmission of information.  In contrast, other talkers (such as Talker~\ac{b}) compensate for lower information density at the segmental level by maintaining prosodic patterns that are conducive to successful transmission of that information.  Put simply, once we set aside the most common causes of misunderstood speech in everyday life (unpredictable background noises, unfamiliar dialects or foreign accents, unexpected content given context, \etc), we still find that not all (un)intelligible talkers are (un)intelligible for the same reasons.

With regard to talker familiarity, it was surprising that listeners failed to realize any advantage due to talker familiarity in Experiment~2.  One possible explanation is that the training was too brief, and the apparent learning seen in the quartile analysis is merely a task familiarization effect that was not tied to any particular talker.  However, previous studies involving speech\-/in\-/noise tests with non\-/native English speakers showed that listeners adapt to even the lowest\-/intelligibility talkers over the course of a single 64-sentence test session \citep{BradlowBent2008}; thus it was predicted that a 90\-/sentence training phase that included both noise\-/masked and clear presentations of each sentence would be sufficient to realize a familiarity advantage that would persist through the testing phase.  Moreover, the fact that the experimental and control groups differed in the magnitude of improvement during training suggests that the listener adaptation that took place was talker\-/specific, at least to some extent.  

Further support for the belief that listener adaptation was talker\-/specific comes if we compare the training phase of Experiment~2 to the testing phase of Experiment~1.  Since Experiment~1 did not involve a training phase, listener adaptation during Experiment~1 occurred during exposure to all nine test “talkers” (three unmodified and six resynthesized), presented in random order.  Thus the improvement seen across quartiles in Experiment~1 (an improvement of 0.39 keywords) cannot possibly be due to talker\-/specific adaptations on the part of the listeners.  Compare this to the magnitude of improvement in the testing phase of Experiment~2, in which listeners in the experimental group (training on Talker~\ac{c}) improved by 0.38 keywords, while listeners in the control group (trained on Talker~\ac{d}) improved by 0.50 keywords.  The fact that listeners in the control group showed greater adaptation during training suggests that there was something about their training talker that enabled that greater adaptation to take place.  

This difference also raises the question of what attribute(s) of Talker~\ac{d}’s speech faciliated the greater adaptation seen in the control group listeners.  It is known from the pilot study that Talker~\ac{d}’s intelligibility is slightly better than Talker~\ac{c} (mean 3.0 \vs\ 2.6 keywords correct in a similar speech\-/in\-/noise task, cf. Section~\ref{sec:pnnc}).  Unfortunately, because Talker~\ac{d} was a control talker and did not appear in the testing phase, it is unknown whether that adaptation would have persisted for the listeners in the control group.  Also unfortunate is the fact that Talker~\ac{d} was not used in the creation of resynthesized stimuli, so it is not known whether his intelligibility rests more on segmental or prosodic aspects of his speech.

%A final consideration in the experimental group’s failure to retain a perceptual advantage between the training and the testing phases is stimulus uncertainty: in the training phase, listeners heard the same talker for 90 sentences in a row, whereas the testing phase comprised a random ordering of sentences from the three unmodified talkers and the six resynthesized talkers.  It is possible that the uncertainty due to varying the talkers negated any advantage acquired from the training.

Regardless of the differences in listener adaptation between listener groups, the fact remains that a listener’s perceptual gain from rapid adaptation to a talker’s speaking style is relatively small in magnitude, compared to the differences in intrinsic intelligibility seen across talkers.  In other words, familiarity with a talker’s speaking style is not enough to transform a mumbler into a clear talker in the ears of the trained listener.  
%On the contrary, the gains due to short\-/term familiarity seem to be (at best) comparable in magnitude to relatively subtle task effects such as random \vs\ blocked stimulus presentation.  This raises the question of whether listener adaptation is relevant to speech perception in cases that do not involve profound mismatches between listener expectations and talker behavior (such as disordered speech, foreign accent, \etc). % TODO: justify the use of "subtle" to describe task effects.  How big are they usually?
Nonetheless, the finding that individuals vary in their intelligibility strategies also helps clarify previous literature, in particular the diversity of acoustic predictors shown to correlate with intelligibility in various studies.  Given that dramatic individual differences were seen in these experiments even among just three talkers, it is unsurprising that prior studies using different samples of talkers diverge in which dimensions of speech best predict the intelligibility of those talkers in their sample.  This raises questions regarding the generalizability of findings for studies where only one or a few talkers are taken to represent the population at large, even in cases where more prominent sources of variability (like dialect or foreign accent) are controlled.

A final theoretical question concerns the generalizability of the patterns described here.  As mentioned in Chapter~\ref{chap:Questions}, the operationalization of prosody as suprasegmental patterns of pitch, loudness, and duration trades on particular facts about English (\ie, its lack of phonemic length distinctions and lexical tones).  Obviously, such a division between segmental and suprasegmental is not so clear\-/cut in a lexical tone language.  The small number of talkers involved also raises the question of whether the variation seen is typical, and whether patterns of segmental dominance \vs\ prosodic dominance vary across dialects, languages, or social groups.
%The approach also trades on particular facts about English compared to other languages: namely, that the dimensions of intensity, \fo, and duration are not primary cues to lexical contrasts in English (at least not in English as commonly spoken in the Pacific Northwest region of the United States).  In other words, English is not a lexical tone language, has no phonemic length contrasts, and there are few lexemes that are distinguished on the basis of syllabic stress location (for which pitch and duration \emph{are} important cues, along with vowel quality).  To the extent that these experiments concern the relative importance to intelligibility of prosodic \vs\ segmental aspects of the signal, the experiments described here also bear some similarity to cue weighting studies, as they constitute an implicit comparision of prosodic cues (taken as a group) \vs\ segmental cues (taken as a group).  

%tie back to cue precision and cue robustness.  Discuss whether patterns will generalize to other environments / types of noise / languages.

\section{Methodological lessons}
TODO: discuss segmentation issues, intensity scaling issues, neutralization \vs\ swapping, quantifying distortion.
% TODO: discuss segmentation issues, esp. with regard to intensity scaling (should have mapped mean or peak instead of contour?)
% TODO: discuss alternative method: neutralize prosody by setting everyone equal to the mean of each dimension
% TODO: measurement or control of the degree of distortion...  how much does it vary from sentence to sentence?


%\section{Potential applications}
%The ability to separate and manipulate prosodic dimensions of speech opens up new experimental paradigms in syntax-phonology interface research, pragmatics, auditory neuroscience, audiology, and psycholinguistics.  Similar to the groundbreaking research in cues and cue trading (where, \eg, a link was found between perceived stop voicing and preceding vowel length), this research opens the door to a more refined understanding of the complex relationships among the acoustic dimensions of loudness, pitch, duration, and timing, on one hand, and the phonological phenomena of stress, focus, and intonation on the other hand.

\section{Future directions}
Perhaps the most interesting application of these findings relates to the fact that some talkers rely on low-frequency modulations (\ie, prosody) as a strategy for maintaining or enhancing intelligibility (indeed, a full ⅓ of the variability in intelligibility appears to be due to prosodic differences).  It has been shown that listeners with hearing impairment rely more strongly on speech envelope cues \citep{LorenziEtAl2006}; thus listeners with hearing impairment ought to perform differently on talkers whose intelligibility relies more on prosody \vs\ talkers whose intelligibility relies more on segmental factors (even in cases where the two talkers are equally intelligible to unimpaired listeners).  That is, for a group of talkers whose unmodified speech is equally intelligible to a group of normal\-/hearing listeners, the talkers could nonetheless be discriminated based on the intelligibility of their prosody when mapped onto some other talker’s speech.  The expected result is that talkers whose prosody degraded intelligibility through resynthesis would be less intelligible to listeners with hearing loss.  Moreover, from a signal\-/processing perspective, low\-/frequency modulations are easier to modify than segmental attributes of the signal (such as consonant release bursts), especially in real\-/time processing applications such as found in hearing aids.
% The methods used in these experiments provide a means of identifying which talkers belong to which group.

Another question raised by this research concerns the relative contributions of duration, \fo, and intensity to intelligibility.  These questions could be addressed with methods similar to those used in this thesis (\ie, prosodic replacement via resynthesis), but they also introduce new complexities.  In particular, the manipulation of one of the dimensions of prosody while holding others constant introduces the possibility of conflicting cues to which syllables are prominent in the utterance.  To do justice to such questions, a preliminary study of how such conflicts are resolved by listeners (and hence how prosodic cues to prominence are weighted) is required.

A final set of questions involves talker familiarity and listener adaptation.  Unfortunately, the experiments in this thesis gave no answer to the question of what underlies the familiar talker advantage.  More research is needed to determine whether listener adaptation to a particular talker rests primarily on segmental or prosodic aspects of speech, or whether some other talker attribute (such as voice quality) is at play.  Given the individual differences seen in these experiments, there are also still questions about individual differences in listener adaptive ability, and whether listeners vary in which dimensions of speech they \term{tune in} to when adapting to a new talker’s speech.  Ultimately, as is often the case in scientific research, we are left with more questions than answers.
% TODO: relate to talkerID?


% a reasonable supposition is that lexical activation allows a listener to more easily characterize a talker with respect to prior experience (\eg, the talker “sounds Southern” or “glottalizes /t/ in coda position”).  This should be testable with talkerID task with two males from dialect A and one talker from each of a few other dialects.  Make sure that the second one doesn't show up until several of the other talkers have been heard, and show (hopefully) that the second male from dialect A is mistaken for the first one.  The idea is to show that talkerID initially relies on the most obvious / highest level differences between talkers, and if listener expectations are manipulated such that they treat “dialect” as the salient level of difference, even if the second talker from dialect A is “closer” to some of the other talkers on various non-dialectal dimensions (\eg, pitch range, stop voicing during closure, etc).
