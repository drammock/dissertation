\chapter{Research questions \& experimental designs\label{chap:Questions}}
% For this reason, the choice between stationary and amplitude\-/modulated maskers necessarily involves a trade\-/off with regard to which cue(s) are most likely to be masked.  Moreover, given the complex interaction between information redundancy on one hand, and cue precision and cue robustness on the other, it is nearly impossible to estimate which portion of perceived information has escaped masking, and which portion has merely been reconstructed by the listener based on past experience or lexico\-/semantic cues.

%Much of the research on intelligibility described in Chapter~\ref{chap:Background} could be classified as one of two types, which I will refer to as the \term{modeling approach} and the \term{controlled manipulation approach} to intelligibility.  Studies using the modeling approach examine two or more speaker populations and attempt to correlate differences in intelligibility with differences in other attributes of the speakers (\eg, speech rate, pitch range, \etc).\footnotemark{}  A major shortcoming of this approach is that naturalistic speech varies among many dimensions simultaneously, so it is difficult to segregate the contributions of the various dimensions being measured.  It is also difficult to know whether variation on a given dimension (\eg, gender) is in fact genuinely contributing to differences in intelligibility, or merely indexing some other unmeasured dimension (\eg, vowel space expansion) that is in fact what listeners are making use of in the perceptual task.

%\footnotetext{Studies of this type include \citet{BondMoore1994, BradlowEtAl1996, HazanMarkham2004, Neel2008}.}

%In contrast, studies using the controlled manipulation approach take a dimension believed to be relevant to the speech perception task, and create stimuli with a known manipulation along that dimension.\footnotemark{}  Such studies allow researchers to segregate the contribution of different dimensions of speech (a good example of this is the separation of talker characteristics “who, where, and when” in \citealt{KitterickEtAl2010}).  However, such studies can be criticized for being too far removed from real\-/world scenarios of speech perception, either because the speech content is too restricted (\ie, sentences in the \ac{crm} corpus), or the experimental conditions are too contrived (\eg, knowing that the target speech will occur in the fourth of the thirteen pairs of talkers, which start at 800 ms intervals, as in \citealt{KitterickEtAl2010}).

%\footnotetext{Examples of this approach include \citet{KiddEtAl2005a, KitterickEtAl2010, DubnoEtAl2012}.}

In Section~\ref{sec:IntelSummary}, a broad distinction was drawn between experiments that \emph{model} intelligibility variation between groups based on measurements of the speech signal, and experiments that \emph{manipulate} some dimension of the stimulus and observe how intelligibility changes as a result.  An ideal compromise would be a series of perception experiments using fully synthetic speech, with complete experimental control over all aspects of the signal.  At present such an approach is prohibitively labor\-/intensive: parametric synthesis of a single sentence can take hours to days, and naturalistic results are difficult to achieve.  Moreover, even if naturalistic synthesis were easy to achieve, listener experience can in no case be controlled so completely, and thus a fairly large corpus of synthetic stimuli would be needed to allow subtle differences in stimulus intelligibility to emerge above the noise inherent in a between\-/subjects experimental design.

The experiments described in this thesis take a hybrid approach between modeling, manipulation, and full\-/blown synthesis.  Stimuli are recorded speech that have been processed to neutralize variation along three dimensions (intensity, \fo, and duration) while preserving variation in others.  In this way, the experiments are most similar to the modeling approach, but with a \term{top\-/down} approach to predictor selection.  In other words, rather than starting with low\-/level measurables (\eg, mean \fo, vowel space size, \etc), these experiments begin with a broad distinction between segmental and suprasegmental aspects of speech, and attempt to determine the contribution of each to speech intelligibility.  

This approach aligns well with the distinction between \term{envelope} and \term{fine structure} cues \citep{Rosen1992}, although the emphasis here is less on temporal scale and more on the linguistic concept of prosody (patterns of duration, intensity, and \fo) \vs\ segmental content.\footnotemark{}  The approach also trades on particular facts about English compared to other languages: namely, that the dimensions of duration, loudness, and pitch are not primary cues to lexical contrasts in English (at least not in English as commonly spoken in the Pacific Northwest region of the United States).  In other words, English is not a lexical tone language, has no phonemic length contrasts, and there are few lexemes that are distinguished on the basis of syllabic stress location (for which pitch and duration \emph{are} important cues, along with vowel quality).  To the extent that these experiments concern the relative importance to intelligibility of prosodic \vs\ segmental aspects of the signal, the experiments described here also bear some similarity to cue weighting studies, as they constitute an implicit comparison of prosodic cues (taken as a group) \vs\ segmental cues (taken as a group).
\footnotetext{Note that segmental content includes both \term{fine structure} and \term{periodicity} cues, collapsing the three\-/way distinction in \citep{Rosen1992}.}

\section{Research questions}
The first research question addressed in this thesis is: {\em how does prosody relate to intelligibility?}  In other words, are differences in intelligibility between talkers attributable (at least in part) to their prosody?  A related question is whether an unintelligible talker can be made more intelligible through prosodic changes alone (without changes to segmental phonetic features like formant transitions, lenited consonants, missing release bursts, \etc).

% What are the relative contributions of the three aspects of prosody (intensity, pitch, duration)?

The second research question concerns the intersection of prosody, intelligibility, and talker familiarity: {\em to what extent is the familiarity advantage relying on prosodic aspects of the talker’s speech?}  In other words, when a  listener is sufficiently attuned to a talker’s voice such that they receive a perceptual advantage from that familiarity, what is it about the talker’s voice that they are \term{tuning in} to?  More concretely, is a novel talker more intelligible if his prosody mimics the prosody of a familiar talker?  Or alternately, will the familiarity advantage persist even when the familiar talker’s prosody changes to mimic the prosody of a novel talker?

\section{Experimental designs\label{sec:ExpDesign}}
Both of the research questions above are investigated through experiments using sentential stimuli resynthesized via \psola{} \citep{MoulinesCharpentier1990}, which allows manipulation of the fundamental frequency and duration of speech (intensity is trivially manipulated by scaling sample magnitudes).  Recordings of a low\-/intelligibility talker can be resynthesized with the prosodic characteristics of a high\-/intelligibility talker (and \vv), allowing comparisons between stimuli that differ in segmental content only or in prosodic content only.  Experiment~1 tests the effect of prosodic replacement on intelligibility by comparing unmodified recordings to stimuli created with prosodic replacement, using three talkers known to vary in their intelligibility in noise.  The processing artifacts that arise during resynthesis (mentioned in Section~\ref{sec:SpeechStyle}) are minimized by several methodological means (described in Chapter~\ref{chap:Methods}) and modeled statistically. 

Experiment~2 investigates the relationship between talker familiarity and prosody, by comparing groups of listeners whose \term{training talker} did or did not match one of the three talkers used in the test sentences.  Experiment~2 includes test sentences resynthesized via the same methods used in Experiment~1.  Listeners in Experiment~2 were grouped based on whether the training talker they heard was or was not among the three talkers in the set of test sentences.

Table~\ref{tab:ExpDesign} schematizes the comparisons of interest in Experiments~1 and~2.  In describing these experiments, the convention adopted is to represent resynthesized \term{talkers} as two\-/letter combinations of the talkers used to achieve the resynthesis.  For example, Talker~\ac{ab} indicates a stimulus made from a recording of Talker~\ac{a}, resynthesized to have the prosody from Talker~\ac{b}’s recording of the same sentence.  Question~1 in Table~\ref{tab:ExpDesign} is addressed by Experiment~1; Questions~2 and~3 are addressed by Experiment~2.

\begin{table}
	\caption[Experimental design schemata]{Schematic table of stimulus types and comparisons for the three experiments described in this thesis.  Unmodified recordings of the three original talkers are represented by letters \ac{a}, \ac{b}, and \ac{c} (Talker~\ac{a} being the most intelligible, and Talker~\ac{c} being the least).  Resynthesized “talkers” are represented by combinations of the letters \ac{a}, \ac{b}, and \ac{c}, with the first letter indicating the \term{segmental donor} and the second letter indicating the \term{prosodic donor} of the resynthesized stimuli.  For experiments involving familiarity, the talker used for training is indicated in (parentheses) preceding the test talker.\label{tab:ExpDesign}}
	\centering
	\begin{tabu} to \textwidth {c X[2,m] c X[-3]}
		\toprule
		\rowfont{\bfseries} & Question & Hypothesis & Intelligibility prediction \\
		\midrule
		1 & Can we shift the intelligibility of a talker by replacing his prosody?    & yes & if \ac{a} > \ac{b} > \ac{c}, then \ac{ab} > \ac{ac}; \ac{ba} > \ac{bc}; \ac{ca} > \ac{cb} \\
		\taburulecolor{ltgray}
		\midrule
%		2 & Does the talker familiarity advantage occur for a new talker with the familiar talker’s prosody? & (AA)BA > (AA)BC \\ 
		2 & Can listeners gain a familiarity advantage based only on prosody?         & yes & if \ac{a} = \ac{b} = \ac{c}, then \ac{(a)ba} > \ac{(a)bc} \\
		\midrule
		3 & Does the talker familiarity advantage persist after prosodic replacement? & yes & if \ac{a} = \ac{b} = \ac{c}, then \ac{(a)ac} > \ac{(a)bc} \\
		\taburulecolor{black}
		\bottomrule
	\end{tabu}
\end{table}

One difficulty with this experimental design is that the predictions, as formulated in Table~\ref{tab:ExpDesign}, are conditional statements, whose antecedents cannot all be true given a fixed choice of three talkers.  In other words, the contribution of prosody to intelligibility is most easily seen when Talkers \ac{a}, \ac{b}, and \ac{c} vary in their base intelligibility, whereas the effect of familiarity is most easily measured when the base intelligibility of the three talkers is known to be equal.  A further complexity is that even the most careful resynthesis introduces some distortion as an artifact of the signal processing, such that listener performance on resynthesized stimuli is expected to be somewhat less than performance on unresynthesized speech.  In analyzing the data reported here, both of these problems are addressed by statistical means using mixed\-/effects regression, such that the effects of prosody, familiarity, and resynthesis are estimated simultaneously, along with estimates of group variance for listener and sentence (see Section~\ref{sec:DataAnal} for details).

%A \ph{} comparison of Experiments~2 and~3 also has the potential to shed light on the talker familiarity advantage.  The motivation for including separate groups for speech\-/in\-/quiet and speech\-/in\-/noise exposure blocks is the hypothesis that the talker familiarity advantage (like speech perception in general) relies (at least in part) on the same cues used for speech recognition, and in particular, relies on whatever cues happen to be available given interfering factors such as environmental noise or listener inattention.  On this view, a familiar talker advantage based on exposure to speech\-/in\-/quiet has access to a wider variety of speech cues than a familiar talker advantage based on exposure to speech\-/in\-/noise, suggesting that exposure to speech\-/in\-/quiet would yield a greater familiarity advantage.  

%However, in a study of {\em task} familiarity, \citet{VanEngen2012} shows that listeners trained with babble\-/masked speech outperform listeners trained with speech\-/shaped\-/noise maskers in a post\-/test using babble\-/masked speech.  This suggests that task similarity between the training and test phases might confer a perceptual advantage, although unfortunately \citeauthor{VanEngen2012} did not test the symmetrical situation (training with either speech\-/shaped noise or babble maskers and testing with speech\-/shaped noise maskers).  Thus the question remains whether training on babble\-/masked speech is simply better than training on speech\-/shaped noise regardless of the target task, or whether task similarity plays a stronger role in determining test performance.  

%An analogous question is at play in Experiments~2 and~3: will the talker familiarity advantage be stronger following exposure to speech\-/in\-/noise (due to task similarity between exposure and test phases), or will the talker familiarity advantage be stronger following exposure to speech\-/in\-/quiet (due to the wider range of cues available)?  A stronger effect of familiarity in Experiment~2 could be interpreted to mean that task similarity is important, perhaps because listeners trained with speech\-/in\-/quiet are \term{tuning in} to speech cues that are insufficiently robust to be reliably recoverable in the test sentences (which are always presented in noise).  In contrast, a stronger effect of familiarity in Experiment~3 would suggest that listeners can and do use all possible speech cues when \term{tuning in} to a familiar talker, and that listeners can make use of high\-/precision cues that happen to escape masking even while primarily relying on high\-/robustness cues when the high\-/precision cues are masked.\footnotemark{}

%\footnotetext{See \citet{Wright2001, Wright2004b} for reviews of cue precision and cue robustness.}


