\chapter{Research questions \& experimental designs\label{chap:Questions}}

\section{Overview}
Much of the research on intelligibility described in Chapter~\ref{chap:Background} could be classified as one of two types, which I will refer to as the \term{modeling approach} and the \term{controlled manipulation approach} to intelligibility.  Studies using the modeling approach examine two or more speaker populations and attempt to correlate differences in intelligibility with differences in other attributes of the speakers (\eg, speech rate, pitch range, \etc).\footnotemark{}  A major shortcoming of this approach is that naturalistic speech varies among many dimensions simultaneously, so it is difficult to segregate the contributions of the various dimensions being measured.  It is also difficult to know whether variation on a given dimension (\eg, gender) is in fact genuinely contributing to differences in intelligibility, or merely indexing some other unmeasured dimension (\eg, vowel space expansion) that is in fact what listeners are making use of in the perceptual task.

\footnotetext{Studies of this type include \citet{BondMoore1994, BradlowEtAl1996, HazanMarkham2004, Neel2008}.}

In contrast, studies using the controlled manipulation approach take a dimension believed to be relevant to the speech perception task, and create stimuli with a known manipulation along that dimension.\footnotemark{}  Such studies allow researchers to segregate the contribution of different dimensions of speech (a good example of this is the separation of talker characteristics “who, where, and when” in \citealt{KitterickEtAl2010}).  However, such studies can also be criticized for being too far removed from real-world scenarios of speech perception, either because the speech content is too restricted (\ie, sentences in the \ac{crm} corpus), or the experimental conditions are too contrived (\eg, knowing that the target speech will occur in the fourth of the thirteen pairs of talkers, which start at 800 ms intervals, as in \citealt{KitterickEtAl2010}).

\footnotetext{Examples of this approach include \citet{KiddEtAl2005a, KitterickEtAl2010, DubnoEtAl2012}.}

The experiments described in this thesis are most similar to the modeling approach, but with a \term{top-down} approach to predictor selection.  In other words, rather than starting with low-level measurables (\eg, mean pitch, vowel space expansion, \etc), these experiments begin with a broad distinction between segmental and suprasegmental aspects of speech, and attempt to determine the contribution of each to the speech intelligibility.  This approach aligns well with the distinction between \term{envelope} and \term{fine structure} cues \citep{Rosen1992}, although the emphasis here is less on temporal scale and more on the linguistic concept of prosody (patterns of duration, intensity, and pitch) \vs\ segmental content.\footnotemark{}  The experiments described here also bear some similarity to cue weighting studies: insofar as they concern the relative importance to intelligibility of prosodic \vs\ segmental aspects of the signal, they constitute an implicit comparision of prosodic cues (taken as a group) \vs\ segmental cues (taken as a group).

\footnotetext{Note that segmental content includes both \term{fine structure} and \term{periodicity} cues, collapsing the three-way distinction in \citep{Rosen1992}.}

\section{Research questions}
The first research question addressed in this thesis is: {\em how does prosody relate to intelligibility?}  In other words, are differences in intelligibility between talkers attributable (at least in part) to their prosody?  A related question is whether an unintelligible talker can be made more intelligible through prosodic changes alone (without changes to segmental phonetic features like formant transitions, lenited consonants, missing release bursts, \etc).

% What are the relative contributions of the three aspects of prosody (intensity, pitch, duration)?

The second research question concerns the intersection of prosody, intelligibility, and talker familiarity: {\em to what extent is the familiarity advantage relying on prosodic aspects of the talker’s speech?}  In other words, when a  listener is sufficiently attuned to a talker’s voice such that they receive a perceptual advantage from that familiarity, what is it about the talker’s voice that they are \term{tuning in} to?  More concretely, is a novel talker more intelligible if his prosody mimics the prosody of a familiar talker?  Or alternately, will the familiarity advantage persist even when the familiar talker’s prosody changes to mimic the prosody of a novel talker?

\section{Experimental designs}
Both of the research questions above are investigated through experiments using sentential stimuli resynthesized via \psola{} \citep{MoulinesCharpentier1990}, which allows manipulation of the pitch and duration of speech (intensity is trivially manipulated by scaling sample magnitudes).  Recordings of a low-intelligibility talker can be resynthesized with the prosodic characteristics of a high-intelligibility talker (and \vv), allowing comparisions between stimuli that differ in segmental content only or in prosodic content only.  Experiment~1 tests the effect of prosodic replacement on intelligibility by comparing unmodified recordings to stimuli created with prosodic replacement, using three talkers known to vary in their intelligibility in noise (see Chapter~\ref{chap:Methods} for details).

Experiment~2 investigates the relationship between talker familiarity and prosody, by comparing groups of listeners whose \term{training talker} did or did not match one of the three talkers used in the test sentences.  Experiment~2 includes test sentences resynthesized via the same methods used in Experiment~1.  Listeners in Experiment~2 were grouped based on whether the training talker they heard was or was not among the three talkers in the set of test sentences.

Table~\ref{tab:ExpDesign} schematizes the comparisons of interest in Experiments~1 and~2.  In describing these experiments, the convention adopted is to represent resynthesized \term{talkers} as two-letter combinations of the talkers used to achieve the resynthesis.  For example, talker \ac{ab} indicates a stimulus made from a recording of talker \ac{a}, resynthesized to have the prosody from talker \ac{b}’s recording of the same sentence.  Question~1 in Table~\ref{tab:ExpDesign} is addressed by Experiment~1; Questions~2 and~3 are addressed by Experiment~2.

\begin{table}
	\caption[Experimental design schemata]{Schematic table of stimulus types and comparisons for the three experiments described in this thesis.  Resynthesized “talkers” are represented by combinations of the letters \ac{a}, \ac{b}, and \ac{c}, with the first letter indicating the \term{segmental donor} and the second letter indicating the \term{prosodic donor} of the resynthesized stimuli (talkers \ac{aa}, \ac{bb}, and \ac{cc} represent the original, unmodified recordings).  For experiments involving familiarity, the talker used for training is indicated in (parentheses) preceding the test talker.\label{tab:ExpDesign}}
	\centering
	\begin{tabu} to \textwidth {cX[2,m]X[-3]}
		\toprule
		\rowfont{\bfseries} & Question & Intelligibility prediction \\
		\midrule
		1 & Can we shift the intelligibility of a talker by replacing his prosody?    & if \ac{aa} > \ac{bb} > \ac{cc}, then \ac{ab} > \ac{ac}; \ac{ba} > \ac{bc}; \ac{ca} > \ac{cb} \\
		\taburulecolor{ltgray}
		\midrule
%		2 & Does the talker familiarity advantage occur for a new talker with the familiar talker’s prosody? & (AA)BA > (AA)BC \\ 
		2 & Can listeners gain a familiarity advantage based only on prosody?         & if \ac{aa} = \ac{bb} = \ac{cc}, then \ac{(aa)ba} > \ac{(aa)bc} \\
		\midrule
		3 & Does the talker familiarity advantage persist after prosodic replacement? & if \ac{aa} = \ac{bb} = \ac{cc}, then \ac{(aa)ac} > \ac{(aa)bc} \\
		\taburulecolor{black}
		\bottomrule
	\end{tabu}
\end{table}

One difficulty with this experimental design is that the predictions, as formulated in Table~\ref{tab:ExpDesign}, are conditional statements, whose antecedents cannot all be true given a fixed choice of three talkers.  A further complexity is that even the most careful resynthesis introduces some distortion, such that listener performance on resynthesized stimuli is predicted to be somewhat less than performance on unresynthesized speech.  Both of these problems are addressed by statistical means using mixed-effects regression, such that the effects of prosody, familiarity, and resynthesis are estimated simultaneously, along with estimates of group variance for listener and sentence (see Chapter~\ref{chap:Methods} for details).

%A \ph{} comparison of Experiments~2 and~3 also has the potential to shed light on the talker familiarity advantage.  The motivation for including separate groups for speech-in-quiet and speech-in-noise exposure blocks is the hypothesis that the talker familiarity advantage (like speech perception in general) relies (at least in part) on the same cues used for speech recognition, and in particular, relies on whatever cues happen to be available given interfering factors such as environmental noise or listener inattention.  On this view, a familiar talker advantage based on exposure to speech-in-quiet has access to a wider variety of speech cues than a familiar talker advantage based on exposure to speech-in-noise, suggesting that exposure to speech-in-quiet would yield a greater familiarity advantage.  

%However, in a study of {\em task} familiarity, \citet{VanEngen2012} shows that listeners trained with babble-masked speech outperform listeners trained with speech-shaped-noise maskers in a post-test using babble-masked speech.  This suggests that task similarity between the training and test phases might confer a perceptual advantage, although unfortunately \citeauthor{VanEngen2012} did not test the symmetrical situation (training with either speech-shaped noise or babble maskers and testing with speech-shaped noise maskers).  Thus the question remains whether training on babble-masked speech is simply better than training on speech-shaped noise regardless of the target task, or whether task similarity plays a stronger role in determining test performance.  

%An analogous question is at play in Experiments~2 and~3: will the talker familiarity advantage be stronger following exposure to speech-in-noise (due to task similarity between exposure and test phases), or will the talker familiarity advantage be stronger following exposure to speech-in-quiet (due to the wider range of cues available)?  A stronger effect of familiarity in Experiment~2 could be interpreted to mean that task similarity is important, perhaps because listeners trained with speech-in-quiet are \term{tuning in} to speech cues that are insufficiently robust to be reliably recoverable in the test sentences (which are always presented in noise).  In contrast, a stronger effect of familiarity in Experiment~3 would suggest that listeners can and do use all possible speech cues when \term{tuning in} to a familiar talker, and that listeners can make use of high-precision cues that happen to escape masking even while primarily relying on high-robustness cues when the high-precision cues are masked.\footnotemark{}

%\footnotetext{See \citet{Wright2001, Wright2004b} for reviews of cue precision and cue robustness.}


